spaCy is a stronger, tough less didactic, alternative to NLTK. I suggest that you use spaCy for your second projectâ€¦
https://spacy.io/

smart replies(like alexa, or siri) are sequence-to-one model, its except the sequence as input, but chooses from predefined set of responses for its output.

# Corpus and Corpora
Corpus is a collection of written or spoken natural language material, stored on computer,
and used to find out how language is used. So more precisely, a corpus is a systematic
computerized collection of authentic language that is used for linguistic analysis as well as
corpus analysis. If you have more than one corpus, it is called corpora.

There are three types of corpus:
1- Monolingual corpus: This type of corpus has one language
2- Bilingual corpus: This type of corpus has two languages
3- Multilingual corpus: This type of corpus has more than one language

# -------------
Will the amount of data be sufficient for solving the problem statement on at least a
proof of concept (POC) basis?
Answer: According to my experience, I would prefer to have at least 500 MB to 1 GB of
data for a small POC.
# -------------
.xml : Some well-known NLP parsers and tools provide results in the .xml format. For
example, the Stanford CoreNLP toolkit provides parser results in the .xml format. This
kind of file format is mainly used to store the results of NLP applications.
.json : The Stanford CoreNLP toolkit provides its results in the .json format. This
kind of file format is mainly used to store results of NLP applications, and it is easy to
display and integrate with web applications.
# ------------- 
Selecting data
Suppose you are working with world tech giants such as Google, Apple, Facebook, and so
on. Then you could easily get a large amount of data, but if you are not working with giants
and instead doing independent research or learning some NLP concepts, then how and
from where can you get a dataset? First, decide what kind of dataset you need as per the
NLP application that you want to develop. Also, consider the end result of the NLP
application that you are trying to build. If you want to make a chatbot for the healthcare
domain, you should not use a dialog dataset of banking customer care. So, understand your
application or problem statement thoroughly.
# ------------- 
What is the difference between a stem and a root?
Stem:
	In order to generate a stem, we need to remove affixes from the word
	From the stem, we can generate the root by further dividing it
	The word Untie is stem
Root:
A root cannot be further divided into smaller morphemes
A stem is generated by using a root plus derivational morphemes
The word tie is root
# ------------- 
Lexical analysis
Lexical analysis is defined as the process of breaking down a text into words, phrases, and
other meaningful elements. Lexical analysis is based on word-level analysis. In this kind of
analysis, we also focus on the meaning of the words, phrases, and other elements, such as
symbols.
Sometimes, lexical analysis is also loosely described as the tokenization process.

Tokenization and lemmatization are processes that are helpful for lexical analysis.
# ------------- 
PoS
In English, POS categories are verb, noun, adjective, adverb, pronoun, preposition,
conjunction, interjection, and sometimes numeral, article, or determiner.
# ------------- 
Lemmatization

Lemmatization can be defined as a process that identifies the correct intended
POS and meaning of words that are present in sentences.

Lemmatization also includes POS tagging to disambiguate the meaning of the
tokens. In this process, the context window is either phrase level or sentence
level.
# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 

# ------------- 


