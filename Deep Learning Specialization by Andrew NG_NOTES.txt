CNN (convolution neural networks) for vision
RNN (recurrent 	 neural networks) and LSTM(Long short-term memory) for sequance data (temporal or NLP)

RELU:
	rectified linear unit
	rectified: if the prediction from linear function is nagative then the prediction is chaneged to 0, so using RELU we get all predictions >= 0

audo is represented one dimontional time series

text, audio, and images are unstructred data. 

much harder for computers to make scence of unstructred data compared to structered data.
  

agar data kafi zyada na ho to ML use karty hen, jahan par koi improvement lany k lye zaroori h k feature enginearing aap khud karen. or agar aap k pas data bohot zyada h to aap us ko DL model me fit kar sakty hen, jahan aap ko feature enginearing ki zaroorat nahi h.

DL k lye zaroori cheezen:
	very large data
	high level hardware (eg: ram and GPU)


logistic regression = sigmoid(linear regression)
relu = linear regression (except that nagative predictions replaced with 0)

relu Vs sigmoid (as activation function):
	in relu the gradian descent run much faster compaired to sigmoid
	in sigmoid there is  nearly flat line in bot tails (upper and lower), so gradiant is nearly 0, so learning become very slow. 

	on the other hand the gradiant is equal to 1 for all positve values of input, so gradiant descent is much faster  

sparce matrix:
	matrix with lot of zeros

Logistic regression:
	we interpret the output of logistic regression as follows:
		probability of y=1 given this observation

	sigmoid function:
		1 / (i- e - linear_equation output)

	if linear_equation output is very large then the this part (e- linear_equation output) will be close to 0, so sigmoid (linear_equation output) will be approximately = 1/1+someting_very_close_to_zero, and thus the output is aproximately 1.  on the other hand if linear_equation output is very small or very large nagative number then sigmoid(linear_equation output) will be approximately = 1/1+someting_very_large, and thus the output is aproximately 0

	when you implement logistic regression your job is to try to learn parameters w and b so that y_hat becomes a good estimate of y

	